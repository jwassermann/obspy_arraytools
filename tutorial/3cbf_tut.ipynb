{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial/notebook will demonstrate three-component beamforming using ObsPy. It will explain every step along the way.\n",
    "\n",
    "Look at the 2003 San Simeon earthquake from the Parkfield array.\n",
    "\n",
    "Interactive so feel free to experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining an Inventory\n",
    "\n",
    "While all important information about the instruments in the array could be\n",
    "obtained from the project's website at [...] and then manually fed into obspy, in this\n",
    "case it is far easier to obtain this 'inventory' data through the webservice \n",
    "provided for the purpose under http://service.ncedc.org/. Because the format of these URLs and the provided webservices are standardised, it is very easy to connect to the NCEDC using obspy:\n",
    "\n",
    "(Execute cells by clicking into them and pressing the 'play' button on top. It might take a little while to connect to the NCEDC's servers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:00.459881Z",
     "start_time": "2021-08-04T10:53:57.038407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the FDSN webservice:\n",
    "from obspy.clients.fdsn import Client\n",
    "ncedc_client = Client(\"NCEDC\")\n",
    "# Check what's in it:\n",
    "print(ncedc_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the FDSN client can provide seismic data, event catalogs, station information, etc. First, we're interested in station information for our network with the code BP. The webservice can provide different levels of information, with 'response' providing full response information for all requested channels. We only want the BP channels (BP1, BP2, BP3) of all stations in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:44.879848Z",
     "start_time": "2021-08-04T10:54:00.461226Z"
    }
   },
   "outputs": [],
   "source": [
    "inv = ncedc_client.get_stations(network=\"BP\", level=\"response\")\n",
    "inv = inv.select(channel=\"BP*\")  # The * is a wildcard.\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a lot more channel objects than you might expect - after all, there should be only three physical BP channels per station. Furthermore, station JCSB is listed twice. The problem is that every channel object is only valid for a certain time; for example until changes to the instrument are made. By specifying your time of interest, you should get only one channel object per physical channel.\n",
    "\n",
    "An obspy inventory is essentially a list of networks, which are lists of stations, which are lists of channels (with some bells and whistles). A good overview of this structure can be found in the [obspy documentation](http://docs.obspy.org/packages/obspy.station.html#class-hierarchy).\n",
    "So, one way to get an individual channel object is to use indices, for example, the BP1 channel of station CCRB (the first in the list) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:44.883884Z",
     "start_time": "2021-08-04T10:54:44.881282Z"
    }
   },
   "outputs": [],
   "source": [
    "print(inv[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This channel, valid for most of 2001 through 2003, can be identified directly by its SEED ID string 'BP.CCRB..BP1'. This is made up of the codes for the network, station, location (blank) and channel, and is used for example in the get_coordinates method of an inventory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:44.892201Z",
     "start_time": "2021-08-04T10:54:44.884962Z"
    }
   },
   "outputs": [],
   "source": [
    "inv.get_coordinates('BP.CCRB..BP1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This location information must be set in either the channel or the station objects to use the array processing methods. Note the warning that more than one set of coordinates was found - this is because several channel objects match that identifier, for different times.\n",
    "\n",
    "As you want to analyse waves from the San Simeon earthquake, it is a good idea to first fetch its event information. One convenient way is to search for earthquakes in the area, using a webservice. Let's stick to the NCEDC's catalogue and search for earthquakes during 2003, of a magnitude larger than 6, within 10 degrees of the array:\n",
    "\n",
    "(Remember to close opened plots, or program execution won't continue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:48.804236Z",
     "start_time": "2021-08-04T10:54:44.893483Z"
    }
   },
   "outputs": [],
   "source": [
    "from obspy.core import UTCDateTime\n",
    "search_location = (inv[0][0][0].latitude, inv[0][0][0].longitude)\n",
    "eqs = ncedc_client.get_events(UTCDateTime(\"2003-01-01T00:00:00.000\"),\n",
    "                              UTCDateTime(\"2004-01-01T00:00:00.000\"),\n",
    "                              minmagnitude=6, latitude=search_location[0],\n",
    "                              longitude=search_location[1], maxradius=10)\n",
    "print(eqs)\n",
    "eqs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only earthquake matching these criteria is the San Simeon earthquake. The Catalog object returned by the webservice contains a list of Event objects, which in turn contain Origin objects listing available information on the source mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:48.808247Z",
     "start_time": "2021-08-04T10:54:48.805264Z"
    }
   },
   "outputs": [],
   "source": [
    "sansim = eqs[0]\n",
    "sansimsource = sansim.origins[0] \n",
    "print(sansim)\n",
    "print(sansimsource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this to define a time span for beamforming. Given the earthquake's proximity to the array, take the origin time as starting time for beamforming, and set the end about two minutes after that. You can then reduce the inventory to the channel objects relevant for that time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:48.815844Z",
     "start_time": "2021-08-04T10:54:48.809707Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = sansimsource.time\n",
    "time_span = 130\n",
    "t_end = t_start + time_span\n",
    "inv = inv.select(starttime=t_start, endtime=t_end)\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the inventory needed for three-component beamforming: three channels per station, with given locations. Note that if you want to analyse data over a time window where several channel objects exist for one physical channel, you must split your data and analysis into separate windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Array\n",
    "\n",
    "Next, set up a SeismicArray object. This is the container for all array analysis routines; for example you can plot the array geometry. You can now also calculate the distance and backazimuth from the centre of the array to the earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:49.808494Z",
     "start_time": "2021-08-04T10:54:48.817135Z"
    }
   },
   "outputs": [],
   "source": [
    "from obspy_arraytools import SeismicArray\n",
    "pfield = SeismicArray('pfield', inventory=inv)\n",
    "pfield.plot()\n",
    "\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "gps2dist_azimuth(pfield.center_of_gravity['latitude'],\n",
    "                 pfield.center_of_gravity['longitude'],\n",
    "                 sansimsource.latitude, sansimsource.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Data\n",
    "\n",
    "Now to get the actual seismic data for analysis. This works very similarly to requesting an inventory. Again, request data from the BP network, for all channels starting with BP, for all available stations and locations. The beamforming requires all traces to be equally long (with the same number of samples), so keep only traces which cover the entire time span. Finally, deconvolve the instrument response to get velocity data and filter to a sensible frequency range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:54.160012Z",
     "start_time": "2021-08-04T10:54:49.809606Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = ncedc_client.get_waveforms(\"BP\", \"*\", \"*\", \"BP*\", t_start, t_end)\n",
    "all_data.attach_response(pfield.inventory)\n",
    "\n",
    "sampling_rate = all_data.traces[0].stats.sampling_rate\n",
    "data = all_data.select(npts=time_span * sampling_rate)\n",
    "\n",
    "data.remove_response(output=\"vel\")\n",
    "vel = data\n",
    "\n",
    "freq_range = [0.1, .5]\n",
    "vel.detrend(type='simple')\n",
    "vel.filter('bandpass', freqmin=freq_range[0], freqmax=freq_range[1])\n",
    "print(vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, station JCNB did not provide data for the entire time, so there are only traces from 12 stations. This is still easily enough for beamforming. You can now update the inventory for the Parkfield array so that it does not list JCNB. This is done automatically when beamforming, but if you want e.g. accurate plots of the array geometry you may choose to do it explicitly. For this script, it is necessary because of the sensor orientation fix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:54.167474Z",
     "start_time": "2021-08-04T10:54:54.161058Z"
    }
   },
   "outputs": [],
   "source": [
    "pfield.inventory_cull(vel)\n",
    "# See the updated inventory:\n",
    "print(pfield.inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing sensor orientation\n",
    "\n",
    "The BP data, being from borehole instruments, presents a problem with its orientation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:54.177122Z",
     "start_time": "2021-08-04T10:54:54.168464Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(st.code, st[0].dip, st[1].azimuth, st[2].azimuth)\n",
    " for st in pfield.inventory[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP1 (st[0]) is perfectly vertical, but the horizontal channels BP2 and BP3 (st[1] and st[2]) are oriented somewhat randomly. To do any sort of beamforming, the data must be oriented in North, East and Up directions. The following fix is somewhat lengthy, so you can simply skip over it (but still execute the code!) if your data is already rotated correctly, but it may be interesting anyway. \n",
    "\n",
    "The horizontal seismic data can of course be tranformed by some simple trigonometric calculations, for which Obspy handily provides functions. Appropriate for this case is a rotation from radial and transverse components to North and East. However, we must first define channels as radial and transverse, and update the trace headers to match. Following a left-handed system of radial, transverse, and up, we define the radial component as that which is 'left' of the other: For example, if the BP3 channel has an azimuth of 90 degrees, and BP2 has 180, BP3 is the radial component with a backazimuth of 270 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:54.187459Z",
     "start_time": "2021-08-04T10:54:54.178057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the inventory:\n",
    "inv2 = pfield.inventory.select(channel=\"BP2\")\n",
    "inv3 = pfield.inventory.select(channel=\"BP3\")\n",
    "# Iterate through the stations in both inventories in parallel, choosing\n",
    "# radial/transverse channels:\n",
    "for st2, st3 in zip(inv2[0], inv3[0]):\n",
    "    bp2 = st2[0].azimuth\n",
    "    bp3 = st3[0].azimuth\n",
    "    if (bp2 - bp3 == 90) or (bp3 >= 270 and bp2 < 90):\n",
    "        radial = bp3\n",
    "    elif (bp3 - bp2 == 90) or (bp2 >= 270 and bp3 < 90):\n",
    "        radial = bp2\n",
    "    else:\n",
    "        raise ValueError(\"Channels aren't at right angles.\")\n",
    "    back_azimuth = radial - 180 if radial >= 180 else radial + 180\n",
    "    new_suffixes = ['T', 'R'] if radial == bp3 else ['R', 'T']\n",
    "\n",
    "    # Streams containing just one trace, for the current station:\n",
    "    current_stream2 = vel.select(channel='BP2', station=st2.code)\n",
    "    current_stream3 = vel.select(channel='BP3', station=st3.code)\n",
    "\n",
    "    # The channel code in the headers of all traces must be changed from e.g.\n",
    "    # BP2 to BPR:\n",
    "    for tr, suffix in zip([current_stream2[0], current_stream3[0]],\n",
    "                          new_suffixes):\n",
    "        tr.stats.channel = tr.stats.channel[:-1] + suffix\n",
    "\n",
    "    # Rotate the seismic data. This updates the\n",
    "    # channel codes of the streams to BPN and BPE.\n",
    "    combined_streams = current_stream2 + current_stream3\n",
    "    combined_streams.rotate('RT->NE', back_azimuth)\n",
    "\n",
    "    # The information in the inventory needs to be updated manually to reflect\n",
    "    # the new channel orientations and codes. Remember st2 and st3 only contain\n",
    "    # a single channel each.\n",
    "    new_N = st2.channels[0] if radial == bp2 else st3.channels[0]\n",
    "    new_E = st3.channels[0] if radial == bp2 else st2.channels[0]\n",
    "    new_N.azimuth = 0\n",
    "    new_N.code = new_N.code[:-1] + 'N'\n",
    "    new_E.azimuth = 90\n",
    "    new_E.code = new_E.code[:-1] + 'E'\n",
    "\n",
    "# Finally, rename the vertical channels in both the data streams and the\n",
    "# inventory:\n",
    "for tr in vel.select(channel='BP1'):\n",
    "    tr.stats.channel = tr.stats.channel[:-1] + 'Z'\n",
    "for st in pfield.inventory.select(channel='BP1')[0]:\n",
    "    for ch in st:\n",
    "        ch.code = ch.code[:-1] + 'Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now oriented in North, East and Up components, with the trace headers and inventory updated to match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beamforming\n",
    "\n",
    "The three-component beamforming follows [Esmersoy1985]_. To use it, you need to decide on some paramaters: The beamforming is performed on a sliding window, for which you need to choose a sensible length, to ensure coherency in the signal, and overlap (default is no overlap which runs\n",
    "fastest). At a minimum, the window length must be long enough to allow a signal with the highest chosen slowness to propagate across the entire array.  It is also possible to average the covariance matrix over a number  of windows. You also need to define a slowness range, as the beamforming is performed for discrete values of slowness. This will partly depend on the chosen wavetype: This algorithm can (with some caveats) distinguish P,\n",
    " SV, Love, and prograde or retrograde Rayleigh waves. Similarly, you need to define a frequency range that most sensibly has the same\n",
    "minimum/maximum as that to which the data was previously filtered.\n",
    "You may also choose to whiten the frequency spectrum before beamforming and/or normalise the\n",
    " resulting powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:54:58.747383Z",
     "start_time": "2021-08-04T10:54:54.188431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a slowness range in seconds per km:\n",
    "s_min, s_max, s_step = [0, 0.6, 0.03]\n",
    "# Define window length in seconds (powers of 2 make for faster Fourier\n",
    "# transforms):\n",
    "window_length = 64\n",
    "# Need separate streams:\n",
    "vel_n = vel.select(channel='BPN')\n",
    "vel_e = vel.select(channel='BPE')\n",
    "vel_z = vel.select(channel='BPZ')\n",
    "out = pfield.three_component_beamforming(vel_n, vel_e, vel_e, window_length,\n",
    "                                         s_min, s_max, s_step, wavetype='P',\n",
    "                                         freq_range=freq_range, whiten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result has a range of plotting options attached. You can also plot the array response function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:55:23.967071Z",
     "start_time": "2021-08-04T10:54:58.748490Z"
    }
   },
   "outputs": [],
   "source": [
    "out.plot_bf_plots(show=False)\n",
    "out.plot_bf_plots(average_windows=False, show=False)\n",
    "out.plot_baz_hist(show=False)\n",
    "out.plot_bf_results_over_time(show=True)\n",
    "\n",
    "out.plot_radial_transfer_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
